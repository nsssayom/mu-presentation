<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mu – Microsecond Consensus for Microsecond Applications</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/theme/white.css" id="theme">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap">
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div class="reveal">
    <div class="slides">

      <!-- ==================== 1. TITLE ==================== -->
      <section class="title-slide" data-background-gradient="linear-gradient(135deg, #0f172a 0%, #1e3a5f 55%, #1e40af 100%)">
        <h1>μ (Mu)</h1>
        <p class="subtitle">Microsecond Consensus for Microsecond Applications</p>
        <p class="authors">
          Marcos K. Aguilera &middot; Naama Ben-David &middot; Rachid Guerraoui<br>
          Virendra Marathe &middot; Athanasios Xygkis &middot; Igor Zablotchi
        </p>
        <p class="venue">OSDI 2020</p>
        <aside class="notes">
          This is Mu, the Greek letter μ, from OSDI 2020. By Aguilera, Ben-David, Guerraoui, Marathe, Xygkis, and Zablotchi.

          The title captures the whole ambition: microsecond consensus for microsecond applications. By the end of this talk, you'll know exactly what that means, why it's hard, and how Mu pulls it off.
        </aside>
      </section>

      <!-- ==================== 2. THE PROBLEM ==================== -->
      <section>
        <h2>The Problem</h2>
        <p>Modern applications do useful work in <strong>microseconds</strong>,
           but fault tolerance adds orders of magnitude more.</p>
        <div class="stats">
          <div class="stat stat-blue">
            <div class="val">10–100s μs</div>
            <div class="lbl">SMR replication overhead</div>
          </div>
          <div class="stat stat-amber">
            <div class="val">10–100s ms</div>
            <div class="lbl">Traditional failover time</div>
          </div>
        </div>
        <div class="callout callout-blue">
          At microsecond scale, the "overhead" <em>is</em> the entire latency budget.<br>
          <strong>You can't just shave cycles — you need a fundamentally different lever.</strong>
        </div>
        <aside class="notes">
          Here's the problem in one sentence. Modern applications finish useful work in a few microseconds. But state machine replication adds tens to hundreds of microseconds of replication overhead, and tens to hundreds of milliseconds of failover time.

          At microsecond scale, that overhead isn't just overhead anymore. It is the entire latency budget. If your application completes in four microseconds and replication adds fifty, replication just became twelve times more expensive than the actual work.

          The paper's central claim: you can't just optimize existing protocols. You need a fundamentally different lever.
        </aside>
      </section>

      <!-- ==================== 3. MOTIVATION ==================== -->
      <section>
        <h2>Where Microseconds Matter</h2>
        <ul>
          <li><strong>Financial trading</strong> — microseconds = money. Replication delay is a direct competitive disadvantage.</li>
          <li><strong>Embedded control</strong> — microseconds = safety. Real-time loops demand ultra-low-latency replication.</li>
          <li><strong>Microservices</strong> — latency compounds across large service graphs. Stateful components (KV stores) sit on critical paths.</li>
        </ul>
        <div class="callout callout-amber">
          If replication adds several microseconds or failover takes milliseconds, it becomes either a
          <strong>competitive disadvantage</strong> or something <strong>dismissed as unavoidable</strong>.
        </div>
        <aside class="notes">
          Why care about microsecond replication? The paper motivates this with three domains.

          Financial trading. Microseconds literally equal money. If your replicated matching engine adds a few extra microseconds, you lose trades to faster competitors.

          Embedded control. Microseconds equal safety. Real-time control loops can only afford fault tolerance if the replication cost is nearly invisible.

          Microservices. Latency compounds across service graphs. If every stateful component on the critical path adds replication overhead, total round-trip time grows multiplicatively.

          Bottom line: if replication costs several microseconds or failover takes milliseconds, people either accept the competitive disadvantage or just skip replication entirely.
        </aside>
      </section>

      <!-- ==================== 4. SMR BACKGROUND ==================== -->
      <section>
        <h2>State Machine Replication (SMR)</h2>
        <ul>
          <li>Each replica keeps a <strong>copy of the application</strong> + a <strong>log of requests</strong></li>
          <li>Leader orders requests, replicates to a <strong>majority</strong>, replicas apply in order</li>
          <li>Majority intersection → no two different values both "committed" for the same slot</li>
          <li>Provides <strong>linearizability</strong>: the service behaves as one copy</li>
        </ul>
        <div class="callout callout-blue">
          <strong>Classic Paxos</strong> uses increasing proposal numbers and a two-phase protocol
          (prepare → accept) with follower responses on the critical path. Each step costs microseconds.
        </div>
        <aside class="notes">
          Before we get to Mu's solution, two pieces of background. First: state machine replication.

          SMR is the gold standard for making a distributed service look like a single, reliable copy. Each replica keeps a copy of the application and a log of client requests. The leader orders requests, replicates them to a majority, and every replica applies entries in the same order. If the application is deterministic, all replicas stay identical.

          Why a majority? Because any two majorities overlap in at least one replica. That overlap prevents two different values from both being committed for the same log slot. This gives you linearizability: the replicated service behaves as a single copy, and every operation takes effect at exactly one instant between call and return.

          Classic Paxos does this with increasing proposal numbers and a two-phase protocol: prepare, then accept, with follower responses on the critical path. Each step costs microseconds. Mu's question is: can we do better?
        </aside>
      </section>

      <!-- ==================== 5. RDMA BACKGROUND ==================== -->
      <section>
        <h2>RDMA: The Lever</h2>
        <ul>
          <li><strong>One-sided operations</strong> (Write, Read) bypass the remote CPU entirely</li>
          <li><strong>Memory Region (MR)</strong> — registered user memory with configurable access flags</li>
          <li><strong>Queue Pair (QP)</strong> — endpoint with state machine (RESET → INIT → RTR → RTS) and access flags</li>
          <li><strong>Reliable Connection (RC)</strong> — reliable, in-order delivery between QP pairs</li>
        </ul>
        <div class="callout callout-green">
          <strong>Key</strong>: Permissions are <em>hardware-enforced</em> by the NIC and can be changed
          dynamically. A remote RDMA write succeeds or fails based on QP/MR permission state.
        </div>
        <aside class="notes">
          Second piece of background: RDMA, Remote Direct Memory Access. This is Mu's lever.

          RDMA gives you one-sided operations, Write and Read, that complete without the remote CPU running any receive code. The NIC transfers data directly into or out of registered memory. That's why RDMA can achieve extremely low latency and low jitter when used carefully.

          But RDMA is not magic shared memory. It has a real protection model. Two objects matter here.

          A Memory Region, or MR, is registered user memory the NIC can access. It carries access flags that control whether remote reads or writes are allowed.

          A Queue Pair, or QP, is the endpoint you post RDMA work requests to. It also has access flags and goes through a state machine: RESET, INIT, RTR, RTS. Mu uses Reliable Connection transport, which provides reliable, in-order delivery between connected QP pairs.

          Here's the critical insight for Mu: these permissions are hardware-enforced. You can set things up so a remote peer can only write if both its QP and the target MR allow it, and you can change those permissions dynamically. A remote RDMA write either succeeds or fails based on the current permission state. That hardware enforcement is exactly what Mu will exploit.
        </aside>
      </section>

      <!-- ==================== 6. MU'S KEY INSIGHT ==================== -->
      <section>
        <h2>Mu's Two Core Ideas</h2>
        <div class="two-col">
          <div>
            <h3>① Silent Followers</h3>
            <p>Leader replicates via <strong>one-sided RDMA writes</strong> into follower logs.
               Followers do <strong>zero network communication</strong> on the fast path.</p>
          </div>
          <div>
            <h3>② Permission = Safety</h3>
            <p>RDMA write permissions as <strong>split-brain prevention</strong>.
               Each replica grants write access to <strong>exactly one leader</strong> at a time.</p>
          </div>
        </div>
        <div class="callout callout-blue">
          "A competing leader's writes <strong>literally fail</strong> because it doesn't have permission."
          This replaces Paxos proposal numbers with <strong>hardware-enforced access control</strong>.
        </div>
        <aside class="notes">
          Mu introduces two ideas that work together.

          First: silent followers. In the common case, the leader replicates by writing directly into each follower's log using one-sided RDMA. Followers do zero network communication on the fast path. No acknowledgments, no participation in the critical path at all. The paper argues this reaches the practical lower bound of what RDMA hardware can do for replication: essentially one round of one-sided operations.

          Second: permission equals safety. Mu makes "who can write to a replica's log" an explicit invariant. Each replica grants RDMA write permission to exactly one leader at a time. So the way Mu prevents two leaders from racing isn't through proposal numbers and follower replies like Paxos. It's through hardware access control: a competing leader's writes literally fail because the NIC rejects them at the hardware level.

          These two ideas together are what make microsecond replication possible while keeping the system safe.
        </aside>
      </section>

      <!-- ==================== 7. ARCHITECTURE ==================== -->
      <section>
        <h2>Two-Plane Architecture</h2>
        <img src="img/architecture.png" class="r-stretch">
        <p class="caption">Replication plane (fast path, one-sided RDMA writes) and Background plane
           (elections, permissions, catch-up) run on separate threads, QPs, and MRs.</p>
        <aside class="notes">
          This figure shows Mu's architecture. The system splits into two planes running on separate threads, separate QPs, and separate MRs.

          The replication plane is the fast path. Its only job is steady-state replication: receive a request, write it to follower logs, commit, respond. Everything about it is optimized for speed.

          The background plane handles everything else: failure detection, leader election, permission management, and catch-up. These operations can tolerate higher latency because they happen rarely, only when something goes wrong or a replica needs to synchronize.

          The key takeaway from this diagram: these two planes are isolated by design. The replication plane never blocks on background operations, and vice versa.
        </aside>
      </section>

      <!-- ==================== 8. THE BACKGROUND PLANE ==================== -->
      <section>
        <h2>The Background Plane</h2>
        <p>While the replication plane is optimized for speed, the background plane handles
           <strong>everything else</strong> — on separate threads, QPs, and MRs for isolation.</p>
        <div class="two-col">
          <div>
            <h3>Responsibilities</h3>
            <ul>
              <li><strong>Failure detection</strong> — pull-score heartbeat monitoring via RDMA reads</li>
              <li><strong>Leader election</strong> — deterministic rule: lowest-ID replica considered alive</li>
              <li><strong>Permission management</strong> — revoke/grant RDMA write access during leader transitions</li>
              <li><strong>Catch-up &amp; recovery</strong> — synchronize lagging or recovering replicas</li>
            </ul>
          </div>
          <div>
            <h3>Why Separate?</h3>
            <ul>
              <li>Background work must <strong>never block</strong> the fast-path replication thread</li>
              <li>Separate QPs prevent control-plane RDMA ops from queuing behind data-plane writes</li>
              <li>Separate MRs prevent permission changes on the background region from
                  disrupting replication MR access</li>
            </ul>
            <div class="callout callout-green" style="margin-top:12px;">
              Isolation by design — not an optimization, but a correctness requirement at μs scale.
            </div>
          </div>
        </div>
        <aside class="notes">
          Let me go deeper on the background plane, because you need to understand it to follow the rest of the talk.

          It has four responsibilities. Failure detection, using pull-score heartbeat monitoring over RDMA reads, which we'll cover later. Leader election, based on a simple rule: the leader is the lowest-ID replica considered alive. Permission management, the revoke-and-grant protocol for RDMA write access during leader transitions. And catch-up and recovery, which synchronizes lagging or recovering replicas.

          Why does this need to be separate? Because background work must never block the fast-path replication thread. If a permission change or catch-up operation stalled the replication thread, you'd lose the microsecond latency guarantee. Separate QPs keep control-plane RDMA operations from queuing behind data-plane writes. Separate MRs keep permission changes on the background region from disrupting replication MR access.

          This isolation isn't an optimization. At microsecond scale, it's a correctness requirement.
        </aside>
      </section>

      <!-- ==================== SECTION: NORMAL OPERATION ==================== -->
      <section class="section-slide" data-background-gradient="linear-gradient(135deg, #1e293b 0%, #334155 100%)">
        <p class="section-num">Part I</p>
        <h2>Normal Operation</h2>
        <p class="section-desc">The fast path when everyone agrees on the leader</p>
        <aside class="notes">
          Let's walk through how Mu actually works, starting with the normal case: the fast path when everyone agrees on who the leader is.
        </aside>
      </section>

      <!-- ==================== FAST PATH ==================== -->
      <section>
        <h2>The Fast Path</h2>
        <div class="two-col">
          <div>
            <ol>
              <li>Client request intercepted by <strong>capture shim</strong> at the leader</li>
              <li>Leader appends to its local log</li>
              <li>Leader <strong>RDMA-writes</strong> entry to each follower's log</li>
              <li>Majority replicated → execute, respond, and <strong>inject</strong> into replicas for replay</li>
            </ol>
            <div class="callout callout-green">
              Reaches the <strong>practical lower bound</strong> of what RDMA hardware can do
              for replication — one "one-sided round."
            </div>
          </div>
          <div class="text-center">
            <img src="img/normal_timeline.png" style="max-height: 380px;">
          </div>
        </div>
        <aside class="notes">
          Picture a system with three replicas. One is the leader, and everyone agrees on that. Each replica has granted RDMA write permission on its log to the current leader, and nobody else.

          A client request arrives. Mu uses a thin "capture and inject" shim that intercepts requests before they reach the application so they can be replicated. Later, it injects them into each replica's application for deterministic replay. The request itself is treated as an opaque byte sequence.

          Now the fast path runs: the leader appends the request to its next log slot, then issues RDMA writes to each follower's log. These are one-sided writes. The follower CPUs aren't involved at all. Once the leader confirms the request is on a majority (for three replicas, that's any two of three), it executes and responds to the client. Followers later notice the new entry in their own local memory and replay it.

          The important point: this is the practical lower bound of what RDMA can do for replication. One round of one-sided writes. You can't do less and still get majority acknowledgment.
        </aside>
      </section>

      <!-- ==================== ANIMATION: REPLICATION IN ACTION ==================== -->
      <section>
        <h2 style="margin-bottom:0.1em;font-size:1.15em;">Replication in Action</h2>
        <svg id="mu-anim" viewBox="0 0 960 510" class="r-stretch" style="max-width:100%;">
          <defs>
            <marker id="arr-b" viewBox="0 0 10 7" refX="9" refY="3.5" markerWidth="9" markerHeight="7" orient="auto-start-reverse"><polygon points="0 0,10 3.5,0 7" fill="#2563eb"/></marker>
            <marker id="arr-g" viewBox="0 0 10 7" refX="9" refY="3.5" markerWidth="9" markerHeight="7" orient="auto-start-reverse"><polygon points="0 0,10 3.5,0 7" fill="#059669"/></marker>
          </defs>

          <!-- ===== STATIC: Client ===== -->
          <rect x="405" y="5" width="150" height="48" rx="10" fill="#f0fdf4" stroke="#059669" stroke-width="1.5"/>
          <text x="480" y="35" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="15" font-weight="600" fill="#065f46">Client</text>

          <!-- ===== STATIC: Leader (R₁) ===== -->
          <rect x="240" y="88" width="480" height="152" rx="12" fill="#eff6ff" stroke="#2563eb" stroke-width="2"/>
          <text x="480" y="109" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="14" font-weight="700" fill="#1e40af">Leader (R₁)</text>
          <!-- CPU/App -->
          <rect x="270" y="122" width="120" height="46" rx="8" fill="#dbeafe" stroke="#93c5fd" stroke-width="1.5"/>
          <text x="330" y="150" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="600" fill="#1d4ed8">CPU / App</text>
          <!-- Log -->
          <text x="548" y="118" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="10" fill="#64748b">Log (Memory Region)</text>
          <rect x="445" y="128" width="50" height="36" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="500" y="128" width="50" height="36" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="555" y="128" width="50" height="36" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="610" y="128" width="50" height="36" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>

          <!-- ===== STATIC: Follower R₂ ===== -->
          <rect x="40" y="320" width="390" height="130" rx="12" fill="#f8fafc" stroke="#94a3b8" stroke-width="1.5"/>
          <text x="235" y="341" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="14" font-weight="700" fill="#475569">Follower (R₂)</text>
          <rect x="65" y="356" width="100" height="42" rx="8" fill="#f1f5f9" stroke="#cbd5e1"/>
          <text x="115" y="381" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="12" fill="#94a3b8">CPU</text>
          <text x="290" y="352" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="10" fill="#94a3b8">Log</text>
          <rect x="195" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="246" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="297" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="348" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>

          <!-- ===== STATIC: Follower R₃ ===== -->
          <rect x="530" y="320" width="390" height="130" rx="12" fill="#f8fafc" stroke="#94a3b8" stroke-width="1.5"/>
          <text x="725" y="341" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="14" font-weight="700" fill="#475569">Follower (R₃)</text>
          <rect x="555" y="356" width="100" height="42" rx="8" fill="#f1f5f9" stroke="#cbd5e1"/>
          <text x="605" y="381" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="12" fill="#94a3b8">CPU</text>
          <text x="780" y="352" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="10" fill="#94a3b8">Log</text>
          <rect x="685" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="736" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="787" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>
          <rect x="838" y="360" width="46" height="34" rx="4" fill="#f8fafc" stroke="#cbd5e1"/>

          <!-- ===== STEP 1: Client sends request ===== -->
          <g class="fragment" data-fragment-index="1">
            <line x1="480" y1="53" x2="480" y2="86" stroke="#059669" stroke-width="2.5" marker-end="url(#arr-g)"/>
            <text x="522" y="73" font-family="Inter,system-ui,sans-serif" font-size="11" font-weight="600" fill="#059669">request</text>
            <rect x="130" y="468" width="700" height="28" rx="8" fill="#f0fdf4" stroke="#bbf7d0"/>
            <text x="480" y="487" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="600" fill="#065f46">① Client sends request to the leader</text>
          </g>

          <!-- ===== STEP 2: Leader appends to local log ===== -->
          <g class="fragment" data-fragment-index="2">
            <line x1="390" y1="145" x2="440" y2="145" stroke="#2563eb" stroke-width="2" marker-end="url(#arr-b)"/>
            <rect x="446" y="129" width="48" height="34" rx="3" fill="#3b82f6"/>
            <text x="470" y="151" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="12" font-weight="700" fill="#fff">v₁</text>
            <rect x="130" y="468" width="700" height="28" rx="8" fill="#eff6ff" stroke="#bfdbfe"/>
            <text x="480" y="487" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="600" fill="#1e40af">② Leader appends entry to its local log</text>
          </g>

          <!-- ===== STEP 3: One-sided RDMA writes ===== -->
          <g class="fragment" data-fragment-index="3">
            <path class="rdma-path" d="M 370 240 C 340 285 275 320 225 358" fill="none" stroke="#2563eb" stroke-width="2.5" stroke-dasharray="10 6" marker-end="url(#arr-b)"/>
            <path class="rdma-path" d="M 590 240 C 620 285 680 320 720 358" fill="none" stroke="#2563eb" stroke-width="2.5" stroke-dasharray="10 6" marker-end="url(#arr-b)"/>
            <text x="275" y="278" font-family="Inter,system-ui,sans-serif" font-size="11" font-weight="700" fill="#2563eb" transform="rotate(-32 275 278)">RDMA Write</text>
            <text x="670" y="278" font-family="Inter,system-ui,sans-serif" font-size="11" font-weight="700" fill="#2563eb" transform="rotate(28 670 278)">RDMA Write</text>
            <!-- CPU bypass overlays -->
            <rect x="65" y="356" width="100" height="42" rx="8" fill="#fef2f2" stroke="#fca5a5" stroke-width="1.5"/>
            <text x="115" y="374" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="10" font-weight="700" fill="#dc2626">CPU idle</text>
            <text x="115" y="390" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="9" fill="#ef4444">✗ not involved</text>
            <rect x="555" y="356" width="100" height="42" rx="8" fill="#fef2f2" stroke="#fca5a5" stroke-width="1.5"/>
            <text x="605" y="374" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="10" font-weight="700" fill="#dc2626">CPU idle</text>
            <text x="605" y="390" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="9" fill="#ef4444">✗ not involved</text>
            <rect x="130" y="468" width="700" height="28" rx="8" fill="#eff6ff" stroke="#bfdbfe"/>
            <text x="480" y="487" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="600" fill="#1e40af">③ One-sided RDMA writes to follower logs — follower CPUs not involved</text>
          </g>

          <!-- ===== STEP 4: Majority committed ===== -->
          <g class="fragment" data-fragment-index="4">
            <rect x="196" y="361" width="44" height="32" rx="3" fill="#3b82f6"/>
            <text x="218" y="381" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="11" font-weight="700" fill="#fff">v₁</text>
            <rect x="686" y="361" width="44" height="32" rx="3" fill="#3b82f6"/>
            <text x="708" y="381" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="11" font-weight="700" fill="#fff">v₁</text>
            <rect x="370" y="260" width="220" height="34" rx="17" fill="#059669"/>
            <text x="480" y="282" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="700" fill="#fff">✓ Majority Committed!</text>
            <text x="480" y="304" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="12" font-weight="600" fill="#059669">~1.3 μs total</text>
            <rect x="130" y="468" width="700" height="28" rx="8" fill="#ecfdf5" stroke="#a7f3d0"/>
            <text x="480" y="487" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="600" fill="#065f46">④ Entry replicated on a majority — committed in ~1.3 μs</text>
          </g>

          <!-- ===== STEP 5: Leader responds ===== -->
          <g class="fragment" data-fragment-index="5">
            <line x1="440" y1="88" x2="440" y2="55" stroke="#059669" stroke-width="2.5" marker-end="url(#arr-g)"/>
            <text x="425" y="74" text-anchor="end" font-family="Inter,system-ui,sans-serif" font-size="11" font-weight="600" fill="#059669">response</text>
            <rect x="130" y="468" width="700" height="28" rx="8" fill="#f0fdf4" stroke="#bbf7d0"/>
            <text x="480" y="487" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="600" fill="#065f46">⑤ Leader executes request and responds to client</text>
          </g>

          <!-- ===== STEP 6: Followers replay ===== -->
          <g class="fragment" data-fragment-index="6">
            <rect x="65" y="356" width="100" height="42" rx="8" fill="#dbeafe" stroke="#3b82f6" stroke-width="1.5"/>
            <text x="115" y="381" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="10" font-weight="700" fill="#1d4ed8">Replaying ▶</text>
            <line x1="192" y1="377" x2="170" y2="377" stroke="#3b82f6" stroke-width="2" marker-end="url(#arr-b)"/>
            <rect x="555" y="356" width="100" height="42" rx="8" fill="#dbeafe" stroke="#3b82f6" stroke-width="1.5"/>
            <text x="605" y="381" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="10" font-weight="700" fill="#1d4ed8">Replaying ▶</text>
            <line x1="682" y1="377" x2="660" y2="377" stroke="#3b82f6" stroke-width="2" marker-end="url(#arr-b)"/>
            <rect x="130" y="468" width="700" height="28" rx="8" fill="#eff6ff" stroke="#bfdbfe"/>
            <text x="480" y="487" text-anchor="middle" font-family="Inter,system-ui,sans-serif" font-size="13" font-weight="600" fill="#1e40af">⑥ Followers independently observe new entries and replay</text>
          </g>
        </svg>
        <aside class="notes">
          Let me walk through this step by step.

          [Click 1] The client sends a request to the leader.

          [Click 2] The leader appends it to the local log. You can see v1 appearing in the first slot.

          [Click 3] Now the key step. The leader fires one-sided RDMA writes to both followers' logs simultaneously. See the dashed blue lines? Those are RDMA writes going through the network. And look at the follower CPUs: they say "CPU idle, not involved." The NIC handles the memory write directly. The follower CPU never executes any code for this.

          [Click 4] Both followers now have v1. The entry is on all three replicas, so it's committed. Total time: about 1.3 microseconds.

          [Click 5] The leader executes the request and sends the response back to the client.

          [Click 6] Finally, followers independently discover the new entry and replay it through their local application copy. This happens asynchronously, off the critical path.

          So in steady state, the pattern is: leader writes into follower logs, followers replay locally, everyone stays in sync, and no follower network traffic touches the critical path.
        </aside>
      </section>

      <!-- ==================== DATA STRUCTURES ==================== -->
      <section>
        <h2>Per-Replica Data Structures</h2>
        <div class="two-col">
          <div class="text-center">
            <img src="img/structures.png" style="max-height: 380px;">
          </div>
          <div>
            <ul>
              <li><strong>Log</strong>: registered memory (MR), writable only by current leader via RDMA</li>
              <li><strong>FUO</strong> (First Undecided Offset): lowest undecided index</li>
              <li><strong>Per-slot</strong>: (proposal number, value) tuple</li>
              <li><strong>Canary byte</strong>: at end of each entry, non-zero when written</li>
            </ul>
          </div>
        </div>
        <aside class="notes">
          Each replica maintains a few key data structures. The log itself is a registered Memory Region, writable only by the current leader over RDMA.

          The First Undecided Offset, FUO, tracks the lowest log index that the replica considers undecided. In steady state, FUO advances as entries get decided and applied.

          Each log slot holds a proposal number and a value.

          And at the end of each entry sits a canary byte, which prevents followers from reading half-written RDMA entries. We'll see how that works next.
        </aside>
      </section>

      <!-- ==================== MAKING IT CORRECT ==================== -->
      <section>
        <h2>Making It Actually Correct</h2>
        <ul>
          <li><strong>Canary byte</strong> — leader sets non-zero when writing; follower checks before trusting.
              Prevents reading half-written RDMA entries.</li>
          <li><strong>Commit piggybacking</strong> — the next write serves as commit signal for the previous slot.
              No explicit "chosen" message needed.</li>
          <li><strong>Log recycling</strong> — circular log reuses entries once all replicas have applied them</li>
          <li><strong>Prepare omission</strong> — if only empty slots seen on confirmed followers, skip the
              prepare phase entirely. Common-case cost → <strong>just one-sided RDMA writes</strong>.</li>
        </ul>
        <aside class="notes">
          Four details make the fast path actually correct.

          First, the canary byte. RDMA writes aren't transactional. A follower could see a partially written log entry if it reads while the leader is mid-write. Mu handles this with a simple trick: the leader places a non-zero canary byte at the end of each entry. The follower checks the canary before trusting the data. On most NIC and NUMA configurations, memory becomes visible left to right, so the canary at the end is the last thing to appear. The paper notes you could use a checksum instead to be robust across all hardware.

          Second, commit piggybacking. Paxos normally sends an explicit "chosen" message. Mu avoids that. Since the leader only moves forward once earlier slots are decided, followers can treat the highest contiguous non-empty prefix of the log as committed, minus possibly the last entry. The next write effectively serves as the commit signal for the previous slot.

          Third, log recycling. The log is circular. Entries get reused once every replica has applied them. We'll see the details when we discuss catch-up.

          Fourth, and most important for performance: prepare omission. Once a leader sees only empty slots at some FUO across its confirmed followers, it skips the prepare phase for all subsequent indices. This is how the common-case cost drops to just one round of one-sided RDMA writes.
        </aside>
      </section>

      <!-- ==================== SECTION: SAFETY & LEADER CHANGE ==================== -->
      <section class="section-slide" data-background-gradient="linear-gradient(135deg, #1e293b 0%, #334155 100%)">
        <p class="section-num">Part II</p>
        <h2>Safety &amp; Leader Change</h2>
        <p class="section-desc">Preventing split-brain, detecting failure, and recovering — at microsecond speed</p>
        <aside class="notes">
          Now for the hard part. The normal case is elegant, but the real challenge in consensus isn't when everyone agrees on the leader. It's preventing split-brain and races between concurrent leaders during failure suspicion, network jitter, or delayed scheduling. This section covers split-brain prevention, failure detection, leader change, edge cases, and recovery.
        </aside>
      </section>

      <!-- ==================== SPLIT-BRAIN ==================== -->
      <section>
        <h2>Why Concurrent Leaders Are Dangerous</h2>
        <div class="two-col">
          <div>
            <h3>Classic Approach</h3>
            <ul>
              <li>Extra message rounds</li>
              <li>Follower promises ("won't accept lower proposals")</li>
              <li>Each round = more μs on the critical path</li>
            </ul>
          </div>
          <div>
            <h3>Mu's Approach</h3>
            <ul>
              <li>Make unauthorized writes <strong>physically impossible</strong></li>
              <li>Not "followers promise" but <strong>"the NIC rejects the write"</strong></li>
              <li>Safety via hardware access control</li>
            </ul>
          </div>
        </div>
        <div class="callout callout-red">
          The hardest part of consensus isn't the normal case — it's preventing split-brain and races
          during failure suspicion, network jitter, or delayed scheduling.
        </div>
        <aside class="notes">
          Why do concurrent leaders matter? If a leader appears slow or dead, another replica will try to take over. Now two replicas both think they're leader, potentially writing different values to the same log slot. That's the split-brain problem.

          The classic fix is extra message rounds and follower promises: "I won't accept proposals with a lower number than yours." Each round adds microseconds to the critical path.

          Mu takes a different approach entirely. Instead of relying on follower promises, it makes unauthorized writes physically impossible. Not "the follower promises not to accept." Rather, "the NIC rejects the write because the QP doesn't have the required permission flags." Safety through hardware access control.

          This is where Mu spends its novelty budget. Not on the happy path, but on the hard case: races during failure suspicion, network jitter, and scheduling delays.
        </aside>
      </section>

      <!-- ==================== PERMISSION-BASED SAFETY ==================== -->
      <section>
        <h2>Permission-Based Safety</h2>
        <div class="two-col">
          <div>
            <h3>The Invariant</h3>
            <ul>
              <li>Each replica grants RDMA write permission on its log to <strong>exactly one leader</strong> at a time</li>
              <li>Hardware enforced: unauthorized RDMA writes <strong>silently fail</strong> at the NIC</li>
              <li>Not "followers promise" — <strong>the NIC rejects the write</strong></li>
            </ul>
            <h3 style="margin-top:0.6em;">How Permissions Change</h3>
            <ol>
              <li>Would-be leader writes a <strong>permission request</strong> into the target replica's
                  background-plane MR (one-sided RDMA)</li>
              <li>Log owner: <strong>revokes</strong> from current holder, <strong>grants</strong> to requester</li>
              <li>Multiple requesters processed <strong>one by one, ordered by replica ID</strong></li>
              <li>Only after revoke+grant → replica joins <code>confirmedFollowers</code></li>
            </ol>
          </div>
          <div>
            <h3>Key Properties</h3>
            <ul>
              <li>Each replica has a <strong>permission request array</strong> in its background-plane MR</li>
              <li>Processing order by ID is <strong>deterministic</strong> — no races between competing candidates</li>
              <li>Old leader's in-flight RDMA writes <strong>silently fail</strong> after revocation — they simply don't land</li>
              <li>The permission switch itself is the <strong>dominant cost</strong> of failover (hundreds of μs)</li>
            </ul>
            <div class="callout callout-red" style="margin-top:12px;">
              This replaces Paxos proposal numbers with <strong>hardware access control</strong>.
              Safety is enforced by the NIC, not by protocol messages.
            </div>
          </div>
        </div>
        <aside class="notes">
          Here's how Mu's permission system works in detail.

          The invariant: each replica grants RDMA write permission on its log to exactly one leader at a time. This is hardware-enforced. If an unauthorized leader tries to write, the NIC silently drops the operation. No error propagates. The data just doesn't land.

          When permissions need to change during a leader transition, the would-be leader writes a permission request into the target replica's background-plane Memory Region. This is itself a one-sided RDMA write into a permission request array that each replica maintains. The log owner's background thread picks up the request, revokes access from the current holder by modifying QP or MR flags, then grants access to the requester. If multiple replicas request simultaneously, they're processed one at a time, ordered by replica ID. That deterministic ordering prevents races between competing candidates.

          Only after this revoke-and-grant cycle completes does the replica join the new leader's confirmed followers set. Any in-flight writes from the old leader silently fail after revocation. They just don't land.

          The permission switch turns out to be the dominant cost of failover: hundreds of microseconds on current NICs. We'll see the exact numbers later. But conceptually, this is the key insight: Paxos proposal numbers get replaced by hardware access control. Safety comes from the NIC, not from protocol messages.
        </aside>
      </section>

      <!-- ==================== CONSENSUS PROTOCOL ==================== -->
      <section>
        <h2>Confirmed Followers &amp; The Protocol</h2>
        <p><code>confirmedFollowers</code>: replicas that granted <strong>exclusive write permission</strong> to this leader.</p>
        <ul>
          <li><strong>Prepare-like</strong>: RDMA-read <code>minProposal</code> from confirmed followers,
              write higher number, read slot at FUO</li>
          <li><strong>Accept-like</strong>: RDMA-write <code>(proposal, value)</code> into FUO slot on
              confirmed followers</li>
        </ul>
        <div class="callout callout-green">
          <strong>Key optimization</strong>: once a leader sees only empty slots at FUO, it
          <strong>omits the prepare phase</strong> for subsequent indices.
          Common-case cost = <strong>just one-sided RDMA writes</strong>.
        </div>
        <aside class="notes">
          Now the consensus protocol itself. Mu maintains a set called "confirmed followers": replicas that have granted exclusive write permission to this leader and revoked it from everyone else. This is stronger than "they replied to a message." It means their NIC permissions guarantee no other leader can concurrently write their logs.

          Mu's propose operation looks like Paxos conceptually, but with a key twist: the leader directly reads and writes follower state through RDMA, treating follower memory as published state.

          The prepare-like step: RDMA-read the minimum proposal number from confirmed followers, pick a higher number, write it back, and read the slot at FUO.

          The accept-like step: RDMA-write the proposal number and value into the FUO slot on confirmed followers.

          The crucial safety condition isn't "followers responded and promised." It's: I only touch replicas whose NIC permissions guarantee no other leader can write to them while I operate.

          And the key optimization: once a leader sees only empty slots at FUO across confirmed followers, it skips the prepare phase entirely for subsequent indices. That's why the common case costs just one round of one-sided RDMA writes.
        </aside>
      </section>

      <!-- ==================== PULL-SCORE ==================== -->
      <section>
        <h2>Pull-Score Failure Detection</h2>
        <div class="two-col">
          <div>
            <h3>Traditional (Push)</h3>
            <ul>
              <li>Leader pushes heartbeats</li>
              <li>Network jitter delays messages</li>
              <li>→ False positives or large timeouts</li>
            </ul>
          </div>
          <div>
            <h3>Mu (Pull-Score)</h3>
            <ul>
              <li>Followers <strong>RDMA-read</strong> leader's counter</li>
              <li>Score: +1 if unchanged, −1 if changed</li>
              <li>Bounded [0, 15]; fail = 2, recover = 6</li>
              <li>Delay → slower scoring, not sudden gaps</li>
            </ul>
          </div>
        </div>
        <div class="callout callout-blue">
          <strong>Two-layer design</strong>: small pull-score threshold for common failures
          (brief stalls, scheduling delays) + longer connection-level timeout for major
          disruptions (network breakage, machine crash). Hysteresis prevents oscillation
          and enables aggressive detection without spurious leader changes.
        </div>
        <aside class="notes">
          How does Mu detect that a leader has failed?

          Traditional push-based heartbeats have the leader send periodic messages. But network jitter delays those messages, so you need conservatively large timeouts to avoid false positives. At microsecond scale, that means you either tolerate slow detection or suffer constant false leader changes.

          Mu uses a pull-based approach instead. Each replica maintains a heartbeat counter that increments as it makes progress. Other replicas periodically RDMA-read that counter. If the counter changed since last check, the score decreases, things look healthy. If it hasn't changed, the score increases, potential problem. Scores are bounded between 0 and 15, with a failure threshold at 2 and a recovery threshold at 6.

          Here's the subtle part. With push heartbeats, network delay creates a sudden silent gap you have to distinguish from real failure. With pull-score, network delay just slows down how fast you accumulate "same value" observations. There's no sudden gap to misinterpret. This lets you set aggressive thresholds without triggering spurious leader changes under normal datacenter conditions.

          There's also a two-layer design. The pull-score threshold handles common, brief failures like scheduling stalls. A longer connection-level timeout handles major disruptions like network breakage or machine crashes. The gap between the failure threshold at 2 and recovery threshold at 6 provides hysteresis that prevents oscillation.
        </aside>
      </section>

      <!-- ==================== ELECTION ==================== -->
      <section>
        <h2>Leader Election &amp; Fate Sharing</h2>
        <ul>
          <li><strong>Policy</strong>: leader = lowest-ID replica considered alive
            <ul><li>Deterministic given "alive" set — no explicit voting needed</li></ul>
          </li>
          <li><strong>Fate sharing</strong>: election thread monitors replication activity
            <ul>
              <li>If replication stuck → leader stops heartbeat → triggers replacement</li>
              <li>Prevents: healthy election thread + stuck replication = silent stall</li>
            </ul>
          </li>
        </ul>
        <div class="callout callout-amber">
          Microsecond behavior is often dominated by engineering pathologies, not algorithmic complexity.
          Fate sharing is a practical fix for a real systems problem.
        </div>
        <aside class="notes">
          Leader election in Mu is simple in policy, careful in mechanism.

          The policy: each replica locally decides that the leader is the lowest-ID replica it considers alive. No voting protocol needed. The goal is determinism: if everyone agrees on who's alive, they automatically agree on the leader.

          But there's a practical complication the paper calls fate sharing. Replication and election run on separate threads, so you can hit a nasty case: the election thread is healthy and the replica appears alive, but the replication thread is stuck. Maybe it hit a bug or lock contention. Progress stalls, but no leader change happens because the failure detector still sees a healthy heartbeat.

          Mu fixes this by having the election thread periodically check whether replication is actually making progress. If it isn't, the election thread stops incrementing the heartbeat counter, which causes other replicas to suspect and replace this leader.

          This is a good example of the paper's mindset. The correctness model comes from distributed algorithms, but microsecond behavior is often dominated by engineering pathologies, not algorithmic complexity. Fate sharing is a practical fix for a real systems problem.
        </aside>
      </section>

      <!-- ==================== LEADER CHANGE ==================== -->
      <section>
        <h2>Leader Change Process</h2>
        <div class="two-col">
          <div>
            <ol>
              <li>Failure detected → local leader rule activates</li>
              <li>New leader <strong>requests permissions</strong> via background plane</li>
              <li>Each follower: <strong>revoke</strong> old, <strong>grant</strong> new</li>
              <li><strong>Catch-up</strong>: copy from most advanced follower</li>
              <li><strong>Update</strong>: push missing entries to lagging replicas</li>
            </ol>
          </div>
          <div class="text-center">
            <img src="img/newleader.png" style="max-height: 380px;">
          </div>
        </div>
        <aside class="notes">
          When a leader is suspected to have failed, the change process has five steps.

          One: the pull-score detector triggers, and the local leader rule kicks in. The next replica in line, the lowest-ID replica still considered alive, starts acting as the new leader.

          Two: the new leader requests permissions from each replica via the background plane, writing into their permission request arrays.

          Three: each replica's background thread processes the request. It revokes write access from the old leader and grants it to the new one.

          Four: the new leader catches up. It reads the FUO from each confirmed follower and copies missing entries from whichever follower is most advanced.

          Five: the new leader pushes missing entries to any lagging replicas and aligns their FUOs.

          The figure on the right shows this visually.
        </aside>
      </section>

      <!-- ==================== EDGE CASES DURING LEADER CHANGE ==================== -->
      <section>
        <h2>Edge Cases During Leader Change</h2>
        <div class="two-col">
          <div>
            <h3>What Can Go Wrong</h3>
            <ul>
              <li><strong>Old leader still alive</strong> — may try to write after being suspected.
                  Its RDMA writes <em>silently fail</em> once permissions are revoked.</li>
              <li><strong>Competing candidates</strong> — multiple replicas suspect the leader simultaneously.
                  Permission manager processes requests <strong>one by one, ordered by replica ID</strong>,
                  ensuring only one wins.</li>
              <li><strong>Partially replicated entries</strong> — old leader wrote to some followers but not a majority.
                  New leader's prepare phase discovers and resolves these via RDMA reads.</li>
            </ul>
          </div>
          <div>
            <h3>Why It Stays Safe</h3>
            <ul>
              <li><code>confirmedFollowers</code> = replicas that <strong>revoked</strong> old leader
                  and <strong>granted</strong> new leader</li>
              <li>New leader only operates on confirmed followers — guaranteed no concurrent writer</li>
              <li>Prepare phase reads slot state to recover any in-flight proposals before proceeding</li>
            </ul>
            <div class="callout callout-green" style="margin-top:12px;">
              Safety doesn't rely on timing or promises — it's enforced by
              <strong>hardware permission state</strong> at the NIC level.
            </div>
          </div>
        </div>
        <aside class="notes">
          Leader change sounds clean on paper, but several edge cases come up.

          The old leader might still be alive. Maybe it was just briefly slow, or the detection was premature. It might try to write after being suspected. This is safe: its RDMA writes silently fail once permissions are revoked. The NIC rejects them.

          Multiple replicas might suspect the leader at the same time and all try to become the new leader. The permission manager handles this by processing requests one at a time, ordered by replica ID. Deterministic ordering means exactly one candidate wins.

          The old leader might have written an entry to some followers but not a majority before losing permission. The new leader's prepare phase discovers these partial entries by RDMA-reading slot state from confirmed followers. It can then complete or override the partial proposal.

          Why does all of this stay safe? The confirmed followers set means what it says: those replicas have revoked the old leader and granted the new one. The new leader only operates on confirmed followers, so there's guaranteed no concurrent writer. The prepare phase reads slot state to resolve any in-flight proposals before moving forward.

          The bottom line: safety doesn't depend on timing or promises. It's enforced by hardware permission state at the NIC.
        </aside>
      </section>

      <!-- ==================== CATCH-UP & RECOVERY ==================== -->
      <section>
        <h2>Catch-Up &amp; Log Recovery</h2>
        <div class="two-col">
          <div>
            <h3>New Leader Catch-Up</h3>
            <ol>
              <li>RDMA-read FUO from each confirmed follower</li>
              <li>Copy missing entries from the <strong>most advanced follower</strong> (highest FUO)</li>
              <li>Push missing entries to <strong>lagging followers</strong> and align their FUOs</li>
            </ol>
            <div class="callout callout-blue" style="margin-top:12px;">
              Without catch-up, any replica outside the confirmed set would drift forever.
              This is what makes Mu a <strong>complete SMR system</strong> — not just a fast-path trick.
            </div>
          </div>
          <div>
            <h3>Circular Log Recycling</h3>
            <ul>
              <li>Each follower tracks a <strong>log-head</strong> pointer (first entry not yet applied)</li>
              <li>Leader RDMA-reads all heads, computes <code>minHead</code></li>
              <li>Entries below minHead safely <strong>zeroed and reused</strong></li>
              <li>Zeroing is critical: canary byte relies on empty entries being distinguishable from written ones</li>
            </ul>
          </div>
        </div>
        <aside class="notes">
          Catch-up and log recovery are what make Mu a complete SMR system, not just a clever fast-path trick.

          When a new leader takes over, all replicas need to be consistent. The catch-up process: RDMA-read the FUO from each confirmed follower, copy missing entries from the most advanced follower, then push what's missing to lagging followers and align their FUOs. Without this, any replica outside the confirmed set would drift indefinitely.

          On the right: circular log recycling, which keeps the log finite. Each follower tracks a log-head pointer, the first entry not yet applied locally. The leader periodically RDMA-reads all head pointers and computes minHead, the minimum across all followers. Entries below minHead are safe to zero out and reuse.

          The zeroing step matters more than it looks. The canary byte mechanism depends on empty entries being distinguishable from written ones. If you reuse a slot without zeroing it, a follower could mistake a stale canary from a previous round for a fresh write. Zeroing guarantees that a non-zero canary always means a freshly written entry.
        </aside>
      </section>

      <!-- ==================== PERMISSION MECHANISMS ==================== -->
      <section>
        <h2>Permission Switch Mechanisms</h2>
        <p>Changing RDMA permissions is far slower than ordinary RDMA operations:</p>
        <div style="margin: 14px 0;">
          <div class="bar-row">
            <span class="bar-lbl">QP Access Flags</span>
            <div class="bar-track"><div class="bar-fill blue" style="width: 8%;">~88 μs</div></div>
          </div>
          <div class="bar-row">
            <span class="bar-lbl">QP State Cycle</span>
            <div class="bar-track"><div class="bar-fill amber" style="width: 25%;">~1,216 μs</div></div>
          </div>
          <div class="bar-row">
            <span class="bar-lbl">MR Re-register</span>
            <div class="bar-track"><div class="bar-fill red" style="width: 95%;">350–56,700 μs</div></div>
          </div>
        </div>
        <div class="callout callout-amber">
          Mu: try QP Flags first (fast, but can error if ops in-flight), fall back to QP State Cycle.
          MR Re-register scales disastrously with region size — a <strong>NIC control-plane bottleneck</strong>.
        </div>
        <aside class="notes">
          Here's something the paper discovered is a surprising bottleneck: the cost of changing RDMA permissions.

          Normal RDMA reads and writes complete in low single-digit microseconds. But changing the permissions that enable safe leader transitions is far slower.

          The paper evaluates three mechanisms. MR re-registration is the most flexible but the most expensive: 350 to 56,700 microseconds, scaling badly with region size. The NIC firmware has to update page tables, and that's a control-plane bottleneck.

          QP access flag changes are much faster at about 88 microseconds, but they can trigger an error state if RDMA operations are in flight when you modify the flags.

          QP state cycling, transitioning through RESET and back to RTS, is robust regardless of in-flight operations but costs about 1,216 microseconds.

          Mu uses a fast-then-slow strategy: try the fast QP flag change first. If it errors because operations were in flight, fall back to the robust QP state cycle.

          This isn't just an implementation detail. It's part of the paper's broader point: microsecond SMR hits hardware control-plane costs that traditional systems never worried about. The fast path runs in microseconds, but leader changes are bounded by what NIC firmware and driver stacks are optimized for.
        </aside>
      </section>

      <!-- ==================== SECTION: EVALUATION ==================== -->
      <section class="section-slide" data-background-gradient="linear-gradient(135deg, #1e293b 0%, #334155 100%)">
        <p class="section-num">Part III</p>
        <h2>Evaluation</h2>
        <p class="section-desc">4-node cluster · 100 Gbps InfiniBand · 3-way replication</p>
        <aside class="notes">
          Let's look at how Mu performs in practice. The evaluation uses a four-node cluster with 100 Gbps InfiniBand, dual Xeon E5-2640 v4 CPUs, Ubuntu 18.04, and Mellanox OFED drivers. They evaluate three-way replication.
        </aside>
      </section>

      <!-- ==================== REPLICATION LATENCY ==================== -->
      <section>
        <h2>Replication Latency</h2>
        <img src="img/exp2_replication.png" class="r-stretch">
        <p class="caption">~1.3 μs median, ~1.6 μs p99. Faster by multiples than Hermes, DARE, APUS — with much tighter tail latency.</p>
        <aside class="notes">
          The headline result: about 1.3 microseconds median replication latency for small in-memory requests, with about 1.6 microseconds at the 99th percentile.

          For payloads up to the RDMA inline threshold, 256 bytes in their setup, latency is roughly flat. Inlined RDMA avoids the extra DMA step of fetching the payload from host memory. Past 256 bytes, latency rises gradually.

          Compared to the baselines (Hermes, DARE, APUS), Mu is faster by multiples in the median and has much tighter tail latency. The paper attributes the competitors' longer tails to two things: involving follower CPUs in the critical path, and serializing multiple RDMA operations whose timing variances compound.
        </aside>
      </section>

      <!-- ==================== STANDALONE VS ATTACHED ==================== -->
      <section>
        <h2>Standalone vs. Attached Performance</h2>
        <img src="img/exp1_usvsus.png" class="r-stretch">
        <p class="caption">Shared-core mode adds ~400ns cache-coherence penalty per request. At μs scale, thread/core topology is a first-order design choice.</p>
        <aside class="notes">
          This figure compares standalone mode, where Mu tight-loops in isolation, versus attached mode, where it's integrated with a real application. Attached mode adds cache and scheduling interference.

          They also compare dedicated-core versus shared-core configurations. Sharing a core incurs about 400 nanoseconds of cache-coherence penalty per request.

          The takeaway: at microsecond scale, thread and core topology is a first-order design choice. A fast algorithm isn't enough. You also need to think about where threads are pinned and how cache lines bounce between cores.
        </aside>
      </section>

      <!-- ==================== E2E LATENCY ==================== -->
      <section>
        <h2>End-to-End Application Latency</h2>
        <img src="img/exp3_e2e.png" class="r-stretch">
        <p class="caption">Mu integrates via a capture/inject shim. Liquibook: 4.08 → 5.55 μs (+35%). HERD: 2.25 → 3.59 μs. Redis/Memcached: +1.5 μs negligible at ~115 μs base. For true μs apps, Mu is the only viable option.</p>
        <aside class="notes">
          This is the more meaningful question: how does replication overhead compare to the application's own work?

          Mu plugs in through its capture-and-inject shim. Liquibook, a financial exchange matching engine, goes from 4.08 microseconds unreplicated to 5.55 microseconds with Mu. That's roughly 35% overhead. HERD, an RDMA key-value store, goes from 2.25 to 3.59 microseconds.

          For TCP-based systems like Redis and Memcached, the base latency is around 115 microseconds, so Mu's extra 1.5 microseconds basically vanishes in the noise.

          The paper's message is clear: for true microsecond applications like Liquibook and HERD, even 1.3 microseconds is a meaningful fraction of total latency. But Mu is the only system in the comparison where that overhead is plausibly acceptable. Every other system adds enough that replication becomes a non-starter for these workloads.
        </aside>
      </section>

      <!-- ==================== FAILOVER ==================== -->
      <section>
        <h2>Failover Performance</h2>
        <img src="img/failover_histogram.png" class="r-stretch">
        <p class="caption">873 μs median failover — sub-millisecond. Permission switch is the dominant cost. Orders of magnitude faster than traditional SMR failover.</p>
        <aside class="notes">
          Mu reports 873 microseconds median failover time. That's sub-millisecond, and orders of magnitude faster than traditional SMR failover, which typically takes tens to hundreds of milliseconds.

          The experiment injects failure by delaying the leader until it becomes unresponsive, triggering pull-score suspicion at the followers. The paper breaks down detection time versus permission switch time, and confirms that the permission switch dominates. That's consistent with the hardware numbers we saw earlier.

          The histogram shows failover times are tightly clustered. The system behaves predictably under failure rather than exhibiting a long tail of recovery times.
        </aside>
      </section>

      <!-- ==================== THROUGHPUT ==================== -->
      <section>
        <h2>Latency vs. Throughput</h2>
        <img src="img/exp7_latthru.png" class="r-stretch">
        <p class="caption">Mu maintains low latency under increasing throughput, comparing favorably against baseline systems across both dimensions.</p>
        <aside class="notes">
          This figure shows latency versus throughput. Mu maintains low latency as throughput increases, comparing well against the baselines across both dimensions.

          The key observation: Mu doesn't sacrifice throughput for low latency. It scales reasonably under increasing load. The baselines that involve follower CPUs in the critical path show steeper latency degradation as load grows.
        </aside>
      </section>

      <!-- ==================== ACHIEVEMENTS ==================== -->
      <section>
        <h2>What Mu Achieves</h2>
        <div class="stats">
          <div class="stat stat-blue">
            <div class="val">~1.3 μs</div>
            <div class="lbl">Replication (median)</div>
          </div>
          <div class="stat stat-green">
            <div class="val">873 μs</div>
            <div class="lbl">Failover (median)</div>
          </div>
        </div>
        <ul>
          <li><strong>Near RDMA lower bound</strong> — common case = one round of one-sided writes</li>
          <li><strong>Linearizability</strong> — strong consistency via hardware-enforced single-writer permissions</li>
          <li><strong>Real application integration</strong> — Liquibook, HERD, Redis, Memcached</li>
          <li><strong>Complete SMR</strong> — leader change, log recycling, catch-up; not just a fast-path trick</li>
        </ul>
        <aside class="notes">
          Let's step back and summarize what Mu achieves.

          About 1.3 microseconds median replication latency. 873 microseconds median failover. Both are the best numbers in the comparison.

          In the common case, it's near the RDMA lower bound: one round of one-sided writes. That's essentially the minimum you can do while still getting majority replication.

          It provides linearizability through hardware-enforced single-writer permissions, not through protocol-level quorum responses.

          It integrates with real applications: Liquibook, HERD, Redis, Memcached. This isn't a simulation or a theoretical exercise.

          And it's complete SMR. Leader change, log recycling, catch-up. Not a fast-path demo, but a system that handles the full lifecycle of replication.
        </aside>
      </section>

      <!-- ==================== LIMITATIONS ==================== -->
      <section>
        <h2>Limitations &amp; Open Questions</h2>
        <ul>
          <li><strong>RDMA required</strong> — targets datacenter/LAN environments, not WAN deployments</li>
          <li><strong>In-memory only</strong> — no durable logging; persistent memory mentioned as future direction</li>
          <li><strong>Permission switch cost</strong> — hundreds of μs on current NICs; a control-plane bottleneck</li>
          <li><strong>Hardware assumptions</strong> — canary scheme relies on NIC/NUMA ordering; checksum alternative adds cost</li>
        </ul>
        <div class="callout callout-amber">
          Mu shifts work from the network data plane to the RDMA control plane. The fast path is
          microseconds — but the slow path remains bounded by what NIC firmware and drivers optimize for.
        </div>
        <aside class="notes">
          The paper is upfront about its limitations.

          RDMA is required. This targets datacenter and LAN environments with InfiniBand or RoCE. Not applicable to WAN.

          It's in-memory only. No durable logging to stable storage. The paper mentions persistent memory as a future direction.

          Permission switching costs hundreds of microseconds on current NICs. The fast-slow QP strategy helps, but the fundamental cost is a hardware control-plane bottleneck.

          The canary byte scheme relies on certain NIC and NUMA placement conditions for left-to-right visibility ordering. The paper sketches a checksum alternative for robustness across hardware, but that adds cost.

          The broader point: Mu shifts work from the network data plane to the RDMA control plane. The fast path is microseconds, but the slow path is bounded by what NIC firmware and drivers are optimized for today.
        </aside>
      </section>

      <!-- ==================== BIGGER PICTURE ==================== -->
      <section>
        <h2>The Bigger Picture</h2>
        <ul>
          <li><strong>Key contribution</strong>: treating RDMA's access control as a <em>distributed systems primitive</em>
              — not just faster transport, but a new safety mechanism</li>
          <li><strong>Pull-score detection</strong> confronts the practical truth that μs failover is dominated by jitter sensitivity</li>
          <li><strong>After Mu</strong>: Acuerdo (ICPP 2022), NetLR (VLDB 2022), Nezha (VLDB 2023),
              persistent-memory replication (OSDI 2023)</li>
          <li><strong>Active trends</strong>: in-network / SmartNIC-assisted replication, moving protocol logic
              into programmable network devices</li>
        </ul>
        <div class="callout callout-green">
          Mu demonstrates that near-microsecond SMR is feasible — and simultaneously exposes the
          <strong>next bottlenecks</strong>: permission-switch control-plane costs, durability,
          and broader deployment models.
        </div>
        <aside class="notes">
          Where does Mu sit in the bigger picture?

          The key contribution is conceptual: treating RDMA's access control as a distributed systems primitive. Not just using RDMA as faster transport, but using its permission model as the core mechanism for preventing split-brain. Others had explored RDMA for replication before, but Mu pushes the idea all the way into a complete SMR system with leader change, log recycling, and real application integration.

          Pull-score is also worth highlighting. It confronts a practical truth: microsecond failover is usually dominated by jitter sensitivity, not algorithmic complexity. Polling a counter over RDMA changes how delay manifests, which lets you lower detection thresholds without constant false elections.

          The field kept moving after Mu. Acuerdo at ICPP 2022 optimized quorum behavior for RDMA-based atomic broadcast. NetLR at VLDB 2022 explored in-network replication. Nezha at VLDB 2023 tackled deployability and performance tradeoffs. OSDI 2023 work addressed the durability gap with persistent-memory replication over RDMA.

          The most honest summary: Mu demonstrates that near-microsecond SMR is feasible when you exploit one-sided RDMA for the fast path and use RDMA permissions for safety. But it also exposes the next set of bottlenecks: permission-switch control-plane costs, durability, and deployment beyond RDMA-equipped datacenters.

          Thank you.
        </aside>
      </section>

    </div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/notes/notes.js"></script>
  <script src="slides.js"></script>
</body>
</html>
